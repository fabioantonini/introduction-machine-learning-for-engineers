{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b19626-2096-4570-a395-1ab0e6048ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install TensorFlow\n",
    "# First, ensure that you have TensorFlow installed. You can install it using pip:\n",
    "# !pip install tensorflow\n",
    "# !pip install pydot\n",
    "# !pip install graphviz\n",
    "# Install graphyz from https://graphviz.org/download/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9a4c44-72b8-4824-bb83-960fa2fd7d34",
   "metadata": {},
   "source": [
    "# The MNIST dataset\n",
    "\n",
    "The MNIST dataset, which stands for the Modified National Institute of Standards and Technology database, is one of the most famous datasets in the field of machine learning and computer vision. Here are some details about the MNIST dataset:\n",
    "\n",
    "### Creator\n",
    "The MNIST dataset was created by Yann LeCun, Corinna Cortes, and Christopher J.C. Burges.\n",
    "\n",
    "### Composition\n",
    "The MNIST dataset contains 70,000 grayscale images of handwritten digits from 0 to 9. These images are divided into a training set of 60,000 images and a test set of 10,000 images. Each image is 28 pixels by 28 pixels, making each image consist of 784 pixels.\n",
    "\n",
    "### Format\n",
    "- **Training set:** 60,000 images and corresponding labels\n",
    "- **Test set:** 10,000 images and corresponding labels\n",
    "- **Image size:** 28x28 pixels\n",
    "- **Grayscale values:** Each pixel value is an integer between 0 and 255, representing the intensity of the pixel (0 is black, 255 is white).\n",
    "\n",
    "### Purpose\n",
    "The MNIST dataset was created as a benchmark for evaluating machine learning models. It is widely used for training and testing in the field of image processing, pattern recognition, and computer vision.\n",
    "\n",
    "### History\n",
    "The MNIST dataset is a subset of a larger set available from NIST. The creators of MNIST took a portion of the NIST dataset and modified it for easier use in machine learning research. They also normalized the data, resized the images, and centered the digits.\n",
    "\n",
    "### Usage\n",
    "The MNIST dataset is used to benchmark and compare the performance of various algorithms. It is often one of the first datasets used when learning about machine learning and neural networks due to its simplicity and well-defined nature.\n",
    "\n",
    "### Examples\n",
    "Each image in the dataset represents a single handwritten digit, and each image is associated with a label indicating the digit (0-9).\n",
    "\n",
    "### Citations\n",
    "If you use the MNIST dataset in your research, it is customary to cite the following paper:\n",
    "\n",
    "```plaintext\n",
    "Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, \"Gradient-based learning applied to document recognition,\" Proceedings of the IEEE, 1998.\n",
    "```\n",
    "\n",
    "### Access\n",
    "The MNIST dataset is freely available and can be downloaded from various sources, including directly through TensorFlow and other machine learning libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4331eb-4f9c-482b-9214-e0d11d0b0d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow Neural Network Tutorial\n",
    "\n",
    "# In this tutorial, we will create a neural network using TensorFlow, one of the most popular deep learning libraries.\n",
    "# We will build a simple neural network with at least three layers and train it on a dataset.\n",
    "# This tutorial assumes you have basic knowledge of Python and machine learning concepts.\n",
    "\n",
    "# Step 1: Install TensorFlow\n",
    "# First, ensure that you have TensorFlow installed. You can install it using pip:\n",
    "# !pip install tensorflow\n",
    "# !pip install pydot\n",
    "# !pip install graphviz\n",
    "\n",
    "# Step 2: Import Required Libraries\n",
    "# We will start by importing the necessary libraries.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Ensure Graphviz is in the system path\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz-12.0.0-win64/bin/'\n",
    "\n",
    "# Step 3: Load and Preprocess the Data\n",
    "# We will use the MNIST dataset, a collection of handwritten digits. TensorFlow provides a simple way to load this dataset.\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Display five items from the dataset\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    axes[i].imshow(x_train[i], cmap='gray')\n",
    "    axes[i].set_title(f'Label: {y_train[i]}')\n",
    "    axes[i].axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Normalize the data\n",
    "x_train = x_train.reshape((x_train.shape[0], 28 * 28)).astype('float32') / 255\n",
    "x_test = x_test.reshape((x_test.shape[0], 28 * 28)).astype('float32') / 255\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Step 4: Build the Neural Network Model\n",
    "# We will create a simple neural network with three layers using TensorFlow's Keras API.\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the input layer and first hidden layer\n",
    "model.add(Dense(128, input_shape=(28*28,), activation='relu'))\n",
    "\n",
    "# Add the second hidden layer\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Step 5: Visualize the Model\n",
    "# Plot the model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Display the model plot\n",
    "from IPython.display import Image\n",
    "Image(filename='model_plot.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2981c0fc-f0a6-456e-912d-2c1c38c198bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Compile the Model\n",
    "# Next, we need to compile the model. We will use the Adam optimizer and categorical cross-entropy loss function.\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 7: Train the Model\n",
    "# We will train the model using the training data.\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "# Step 8: Evaluate the Model\n",
    "# Finally, we will evaluate the model using the test data.\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "\n",
    "# Step 9: Make a Prediction\n",
    "# Let's take one item from the test set and make a prediction\n",
    "index = 0  # You can change this index to test different items\n",
    "test_image = x_test[index].reshape(1, 28 * 28)\n",
    "prediction = model.predict(test_image)\n",
    "predicted_label = np.argmax(prediction)\n",
    "true_label = np.argmax(y_test[index])\n",
    "\n",
    "# Display the test image and prediction result\n",
    "plt.imshow(x_test[index].reshape(28, 28), cmap='gray')\n",
    "plt.title(f'Predicted: {predicted_label}, True: {true_label}')\n",
    "plt.show()\n",
    "\n",
    "# Check if the prediction is correct\n",
    "if predicted_label == true_label:\n",
    "    print(f'Correct prediction: {predicted_label}')\n",
    "else:\n",
    "    print(f'Incorrect prediction: Predicted {predicted_label}, but true label is {true_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b45034-cc14-4cb5-b70a-ceb27f0e0a69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
